{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c09e21-f414-4495-b033-23a9b7cc5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc968b11-2d2e-4889-bb88-7debdff49396",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2800ef5e-3344-4e35-9fe5-3ec64d7c9800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37af8026-07bf-44a5-b57b-9d999f6ba754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5879ee46-718d-4abe-8437-30660912f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are actually converting all text into lower case because upper case and lower case are t reated as different objects irrespective of the fact that they refer to the same thing.\n",
    "data['review']=data['review'].str.lower()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3b5a94-5f72-43e9-b882-e4d785a4ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4442cdf5-b4c9-43c1-94c5-cead33e15221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML tags using function\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>') # This creates a regex pattern that will help us to find out the html tags in our text\n",
    "    return pattern.sub(r'',text) # This replaces our html tags with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f3b984-1d3b-4e55-aa86-16c57f87421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']=data['review'].apply(remove_html_tags)\n",
    "# apply() function is used to apply a function to every element, row or column of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92778cf1-5871-44aa-8f66-b3fd642af3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. the plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). while some may be disappointed when they realize this is not match point 2: risk addiction, i thought it was proof that woody allen is still fully in control of the style many of us have grown to love.this was the most i\\'d laughed at one of woody\\'s comedies in years (dare i say a decade?). while i\\'ve never been impressed with scarlet johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.this may not be the crown jewel of his career, but it was wittier than \"devil wears prada\" and more interesting than \"superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data['review'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accbe082-9cb1-4720-9dbf-7aaa2680314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URL using function\n",
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297366ff-8ee7-4ba5-8625-f700293ab29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']=data['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0612c332-6874-4dc2-8465-649f591fd40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Punctuation handling\n",
    "import string\n",
    "exclude=string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65802543-bafe-4b19-9fab-359e9056d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two methods of removing punctuations\n",
    "# Method 1\n",
    "def remove_pnc(text):\n",
    "    for i in exclude:\n",
    "        text=text.replace(i,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4495df-ccfa-4568-956e-b9b9b1228804",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='string.With.Punctuation<>!?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0293fc7a-3d1c-47eb-abeb-66cc3fee3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stringWithPunctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Comparing the running time for both the methods to see which one is better\n",
    "import time\n",
    "start=time.time()\n",
    "print(remove_pnc(text))\n",
    "time1=time.time()-start\n",
    "print(time1*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c64e289b-3a62-46a5-a537-9c9da544a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ef7e45a-88c8-47a1-9af9-853f95a49379",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1='string.With.Punctuation<>;,%!?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f4c24c7-59c0-4b4a-8665-b333c99f7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stringWithPunctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "print(remove_punc1(text1))\n",
    "time2=time.time()-start\n",
    "print(time2*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dbce244-b860-443d-9cc1-ba8c3ba3da62",
   "metadata": {},
   "outputs": [],
   "source": [
    " data['review']=data['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de10ced6-7016-4232-b86f-529cc107e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_forms_dict = {\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bbl\": \"be back later\",\n",
    "    \"bfn\": \"bye for now\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"cu\": \"see you\",\n",
    "    \"cya\": \"see you\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"dyk\": \"did you know\",\n",
    "    \"ez\": \"easy\",\n",
    "    \"f2f\": \"face to face\",\n",
    "    \"fml\": \"fuck my life\",\n",
    "    \"ftw\": \"for the win\",\n",
    "    \"fwiw\": \"for what it's worth\",\n",
    "    \"fy\": \"for you\",\n",
    "    \"fyp\": \"for you page\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"g2g\": \"got to go\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"idc\": \"I don’t care\",\n",
    "    \"idk\": \"I don’t know\",\n",
    "    \"ikr\": \"I know, right?\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"imho\": \"in my humble opinion\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"nvm\": \"never mind\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"oof\": \"ouch\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"plz\": \"please\",\n",
    "    \"pov\": \"point of view\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"rn\": \"right now\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"sry\": \"sorry\",\n",
    "    \"sup\": \"what’s up?\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"tbf\": \"to be fair\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"txt\": \"text\",\n",
    "    \"wbu\": \"what about you?\",\n",
    "    \"wyd\": \"what are you doing?\",\n",
    "    \"wym\": \"what you mean?\",\n",
    "    \"wtf\": \"what the fuck\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"yw\": \"you're welcome\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5184e8e8-f68e-433e-a82c-f2d91e33adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convering all abbreviations into their full forms\n",
    "def chat_conversation(text):\n",
    "    new_text=[]\n",
    "    for i in text.split():\n",
    "        if(i.lower() in short_forms_dict):\n",
    "            new_text.append(short_forms_dict[i.lower()])\n",
    "        else:\n",
    "            new_text.append(i)\n",
    "    return \" \".join(new_text) # It is used to join each element of an iterable like list, tuple etc. into a string with \" \" as separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b3b26c-437a-4a82-b66b-4450ba59aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review']=data['review'].apply(chat_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd3b6f90-2302-4ca8-b73d-887b1670aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\megha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ac3b9da-d063-483e-8c41-9bd5fc626724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de1d541-f2ce-46e2-9da7-580c82defa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for i in text.split():\n",
    "        if i in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(i)\n",
    "    x=new_text[:] # Creates a shallow copy\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a14efc5b-e23c-45f2-87ef-e79f0104ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming is the process of reducing all the verb forms of a word to its simplest form\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(i) for i in text.split()])\n",
    "# Lemmatization is another such method similar to stemming but it returns a more readable output as compared to stemming. But lemmatization is slow as compared to stemming. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
